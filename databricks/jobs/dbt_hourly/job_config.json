{
  "name": "DBT Hourly Models Execution",
  "description": "Automated hourly execution of dbt models for data pipeline",
  "job_clusters": [
    {
      "job_cluster_key": "dbt_cluster",
      "new_cluster": {
        "cluster_name": "dbt-hourly-job-cluster",
        "spark_version": "13.3.x-scala2.12",
        "node_type_id": "i3.xlarge",
        "num_workers": 2,
        "spark_conf": {
          "spark.databricks.cluster.profile": "singleNode",
          "spark.master": "local[*]"
        },
        "custom_tags": {
          "purpose": "dbt-execution",
          "team": "data-platform"
        },
        "init_scripts": [
          {
            "workspace": {
              "destination": "/Workspace/Repos/your-repo/scripts/install_dbt.sh"
            }
          }
        ]
      }
    }
  ],
  "tasks": [
    {
      "task_key": "run_dbt_models",
      "description": "Execute dbt models with optional model selection",
      "job_cluster_key": "dbt_cluster",
      "notebook_task": {
        "notebook_path": "/Workspace/Repos/your-repo/databricks/dbt_hourly_job",
        "base_parameters": {
          "env": "prod",
          "models": "",
          "skip_tests": "false"
        }
      },
      "timeout_seconds": 7200,
      "max_retries": 2,
      "min_retry_interval_millis": 300000
    }
  ],
  "schedule": {
    "quartz_cron_expression": "0 0 * * * ?",
    "timezone_id": "UTC",
    "pause_status": "UNPAUSED"
  },
  "email_notifications": {
    "on_start": [],
    "on_success": ["your-email@company.com"],
    "on_failure": ["your-email@company.com", "data-team@company.com"],
    "no_alert_for_skipped_runs": false
  },
  "webhook_notifications": {
    "on_start": [],
    "on_success": [
      {
        "id": "slack-success-webhook"
      }
    ],
    "on_failure": [
      {
        "id": "slack-failure-webhook"
      }
    ]
  },
  "timeout_seconds": 0,
  "max_concurrent_runs": 1,
  "format": "MULTI_TASK"
}